{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4bf1e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37cfc2ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/torch/cuda/__init__.py:88: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 10020). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0e1ecf8dc2d43c9a04948382641f42e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/481 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc759cc6166143b9afdf77ed5edd60d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0877851e49ec496795cb81b99ed56d81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "093b944fc52742189c4cf36ac8278288",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5054dc79e9b6486f868bd215c3c1748e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/501M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'BERTopic' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mflair\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TransformerDocumentEmbeddings\n\u001b[1;32m      3\u001b[0m roberta \u001b[38;5;241m=\u001b[39m TransformerDocumentEmbeddings(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroberta-base\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m topic_model \u001b[38;5;241m=\u001b[39m \u001b[43mBERTopic\u001b[49m(embedding_model\u001b[38;5;241m=\u001b[39mroberta)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'BERTopic' is not defined"
     ]
    }
   ],
   "source": [
    "from flair.embeddings import TransformerDocumentEmbeddings\n",
    "\n",
    "roberta = TransformerDocumentEmbeddings('roberta-base')\n",
    "# topic_model = BERTopic(embedding_model=roberta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87c70749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flair\n",
      "  Downloading flair-0.11.3-py3-none-any.whl (401 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m401.9/401.9 KB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting segtok>=1.5.7\n",
      "  Downloading segtok-1.5.11-py3-none-any.whl (24 kB)\n",
      "Collecting janome\n",
      "  Downloading Janome-0.4.2-py2.py3-none-any.whl (19.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: regex in /opt/conda/lib/python3.9/site-packages (from flair) (2022.10.31)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/lib/python3.9/site-packages (from flair) (2.8.2)\n",
      "Requirement already satisfied: tqdm>=4.26.0 in /opt/conda/lib/python3.9/site-packages (from flair) (4.64.0)\n",
      "Collecting langdetect\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 KB\u001b[0m \u001b[31m40.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting gensim>=3.4.0\n",
      "  Downloading gensim-4.2.0-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (24.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.0/24.0 MB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting mpld3==0.3\n",
      "  Downloading mpld3-0.3.tar.gz (788 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m788.5/788.5 KB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting lxml\n",
      "  Downloading lxml-4.9.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (7.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.9/site-packages (from flair) (0.11.1)\n",
      "Collecting gdown==4.4.0\n",
      "  Downloading gdown-4.4.0.tar.gz (14 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: torch!=1.8,>=1.5.0 in /opt/conda/lib/python3.9/site-packages (from flair) (1.13.0)\n",
      "Requirement already satisfied: matplotlib>=2.2.3 in /opt/conda/lib/python3.9/site-packages (from flair) (3.5.1)\n",
      "Collecting conllu>=4.0\n",
      "  Downloading conllu-4.5.2-py2.py3-none-any.whl (16 kB)\n",
      "Collecting ftfy\n",
      "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 KB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting wikipedia-api\n",
      "  Downloading Wikipedia-API-0.5.4.tar.gz (18 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting tabulate\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Collecting konoha<5.0.0,>=4.0.0\n",
      "  Downloading konoha-4.6.5-py3-none-any.whl (20 kB)\n",
      "Collecting more-itertools\n",
      "  Downloading more_itertools-9.0.0-py3-none-any.whl (52 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.8/52.8 KB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: transformers>=4.0.0 in /opt/conda/lib/python3.9/site-packages (from flair) (4.25.1)\n",
      "Collecting pptree\n",
      "  Downloading pptree-3.1.tar.gz (3.0 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting deprecated>=1.2.4\n",
      "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/lib/python3.9/site-packages (from flair) (1.0.2)\n",
      "Collecting bpemb>=0.3.2\n",
      "  Downloading bpemb-0.3.4-py3-none-any.whl (19 kB)\n",
      "Collecting sentencepiece==0.1.95\n",
      "  Downloading sentencepiece-0.1.95-cp39-cp39-manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting hyperopt>=0.2.7\n",
      "  Downloading hyperopt-0.2.7-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting sqlitedict>=1.6.0\n",
      "  Downloading sqlitedict-2.0.0.tar.gz (46 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.3/46.3 KB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.9/site-packages (from gdown==4.4.0->flair) (4.10.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.9/site-packages (from gdown==4.4.0->flair) (3.8.0)\n",
      "Requirement already satisfied: requests[socks] in /opt/conda/lib/python3.9/site-packages (from gdown==4.4.0->flair) (2.27.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.9/site-packages (from gdown==4.4.0->flair) (1.15.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (from bpemb>=0.3.2->flair) (1.21.6)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /opt/conda/lib/python3.9/site-packages (from deprecated>=1.2.4->flair) (1.12.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /opt/conda/lib/python3.9/site-packages (from gensim>=3.4.0->flair) (5.2.1)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /opt/conda/lib/python3.9/site-packages (from gensim>=3.4.0->flair) (1.8.0)\n",
      "Collecting py4j\n",
      "  Downloading py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.5/200.5 KB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: cloudpickle in /opt/conda/lib/python3.9/site-packages (from hyperopt>=0.2.7->flair) (2.0.0)\n",
      "Requirement already satisfied: networkx>=2.2 in /opt/conda/lib/python3.9/site-packages (from hyperopt>=0.2.7->flair) (2.7.1)\n",
      "Collecting future\n",
      "  Downloading future-0.18.2.tar.gz (829 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m829.2/829.2 KB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting importlib-metadata<4.0.0,>=3.7.0\n",
      "  Downloading importlib_metadata-3.10.1-py3-none-any.whl (14 kB)\n",
      "Collecting overrides<4.0.0,>=3.0.0\n",
      "  Downloading overrides-3.1.0.tar.gz (11 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=2.2.3->flair) (9.1.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=2.2.3->flair) (1.4.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=2.2.3->flair) (4.31.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=2.2.3->flair) (21.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=2.2.3->flair) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib>=2.2.3->flair) (3.0.7)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.9/site-packages (from scikit-learn>=0.21.3->flair) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from scikit-learn>=0.21.3->flair) (3.1.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /opt/conda/lib/python3.9/site-packages (from torch!=1.8,>=1.5.0->flair) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /opt/conda/lib/python3.9/site-packages (from torch!=1.8,>=1.5.0->flair) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /opt/conda/lib/python3.9/site-packages (from torch!=1.8,>=1.5.0->flair) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /opt/conda/lib/python3.9/site-packages (from torch!=1.8,>=1.5.0->flair) (11.7.99)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.9/site-packages (from torch!=1.8,>=1.5.0->flair) (4.4.0)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch!=1.8,>=1.5.0->flair) (0.37.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch!=1.8,>=1.5.0->flair) (59.8.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.9/site-packages (from transformers>=4.0.0->flair) (5.4.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.9/site-packages (from transformers>=4.0.0->flair) (0.13.2)\n",
      "Requirement already satisfied: wcwidth>=0.2.5 in /opt/conda/lib/python3.9/site-packages (from ftfy->flair) (0.2.5)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.9/site-packages (from importlib-metadata<4.0.0,>=3.7.0->konoha<5.0.0,>=4.0.0->flair) (3.8.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests[socks]->gdown==4.4.0->flair) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests[socks]->gdown==4.4.0->flair) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests[socks]->gdown==4.4.0->flair) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests[socks]->gdown==4.4.0->flair) (2.0.12)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.9/site-packages (from beautifulsoup4->gdown==4.4.0->flair) (2.3.1)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.9/site-packages (from requests[socks]->gdown==4.4.0->flair) (1.7.1)\n",
      "Building wheels for collected packages: gdown, mpld3, sqlitedict, langdetect, pptree, wikipedia-api, overrides, future\n",
      "  Building wheel for gdown (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gdown: filename=gdown-4.4.0-py3-none-any.whl size=14759 sha256=13fb96c28dacba1ee4c5cc0496d8cfa4882229bd30c6130f0fe32e1750a3694e\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/7d/37/b6/b2a79c75e898c0b8e46ff255102602d7159a10d9af0d80641a\n",
      "  Building wheel for mpld3 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for mpld3: filename=mpld3-0.3-py3-none-any.whl size=116702 sha256=cd2973ca6d627e1482af7862182443f5faa4dec11baa71f8b71102c2be1bd308\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/a6/f4/e6/e40ff9021f6b3854af70fa8ea004f5ab95672817462df08fed\n",
      "  Building wheel for sqlitedict (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sqlitedict: filename=sqlitedict-2.0.0-py3-none-any.whl size=15736 sha256=3a0c30363a6b3280cbc761570ac5de0237a057e651a641008051322b3938329e\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/48/a5/80/fa89dc26af0f4c280b500f5529978552379c1ce8907e0a281c\n",
      "  Building wheel for langdetect (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993242 sha256=974c80de2cb6a0228fcd1c2d45d1d44cefbc8feb73eca2a30662e9549da8f016\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/d1/c1/d9/7e068de779d863bc8f8fc9467d85e25cfe47fa5051fff1a1bb\n",
      "  Building wheel for pptree (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pptree: filename=pptree-3.1-py3-none-any.whl size=4629 sha256=330a443ae213267376fdcc58a006176ab49a379ef75f9799923cafb686cdadec\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/52/0e/51/514e690004ea9713bc3fdb678d5e2768fcc597d0c3b6a3abd2\n",
      "  Building wheel for wikipedia-api (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wikipedia-api: filename=Wikipedia_API-0.5.4-py3-none-any.whl size=13477 sha256=e08f955ccfa5e26c5a73ac4ca072ebe1f2aa4bf874024e088e914c737ebe9f97\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/c7/cf/1a/c300428dd51654cdadc921abdff75acaa7cc80b7151a2f0695\n",
      "  Building wheel for overrides (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for overrides: filename=overrides-3.1.0-py3-none-any.whl size=10187 sha256=883aacfa52b96228ff31713e870375cd874736c46a0a2861522ee611080e151c\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/7d/11/0e/73fdcb3d71d97e33c230900efe85923ee9d49515d050503174\n",
      "  Building wheel for future (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=35346ff485660287eab53b1e9484b098ed97abc72b99486b7c3f8693dc669703\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/2f/a0/d3/4030d9f80e6b3be787f19fc911b8e7aa462986a40ab1e4bb94\n",
      "Successfully built gdown mpld3 sqlitedict langdetect pptree wikipedia-api overrides future\n",
      "Installing collected packages: sqlitedict, sentencepiece, py4j, pptree, overrides, mpld3, janome, tabulate, segtok, more-itertools, lxml, langdetect, importlib-metadata, future, ftfy, deprecated, conllu, wikipedia-api, konoha, hyperopt, gensim, gdown, bpemb, flair\n",
      "  Attempting uninstall: sentencepiece\n",
      "    Found existing installation: sentencepiece 0.1.97\n",
      "    Uninstalling sentencepiece-0.1.97:\n",
      "      Successfully uninstalled sentencepiece-0.1.97\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 4.11.3\n",
      "    Uninstalling importlib-metadata-4.11.3:\n",
      "      Successfully uninstalled importlib-metadata-4.11.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "markdown 3.3.6 requires importlib-metadata>=4.4; python_version < \"3.10\", but you have importlib-metadata 3.10.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed bpemb-0.3.4 conllu-4.5.2 deprecated-1.2.13 flair-0.11.3 ftfy-6.1.1 future-0.18.2 gdown-4.4.0 gensim-4.2.0 hyperopt-0.2.7 importlib-metadata-3.10.1 janome-0.4.2 konoha-4.6.5 langdetect-1.0.9 lxml-4.9.1 more-itertools-9.0.0 mpld3-0.3 overrides-3.1.0 pptree-3.1 py4j-0.10.9.7 segtok-1.5.11 sentencepiece-0.1.95 sqlitedict-2.0.0 tabulate-0.9.0 wikipedia-api-0.5.4\n"
     ]
    }
   ],
   "source": [
    "roberta.t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "637ab506",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2682868/888199150.py:1: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(\"all_data/data.csv\")\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"all_data/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "71176482",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>references</th>\n",
       "      <th>year</th>\n",
       "      <th>lang</th>\n",
       "      <th>volume</th>\n",
       "      <th>page_start</th>\n",
       "      <th>doi</th>\n",
       "      <th>title</th>\n",
       "      <th>issue</th>\n",
       "      <th>isbn</th>\n",
       "      <th>authors</th>\n",
       "      <th>...</th>\n",
       "      <th>fos</th>\n",
       "      <th>n_citation</th>\n",
       "      <th>page_end</th>\n",
       "      <th>keywords</th>\n",
       "      <th>url</th>\n",
       "      <th>author_ids</th>\n",
       "      <th>author_names</th>\n",
       "      <th>venue_id</th>\n",
       "      <th>venue_name</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['53e9a8a9b7602d97031f6bb9', '599c7b6b601a182c...</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2461</td>\n",
       "      <td>10.1109/ISCAS.2005.1465124</td>\n",
       "      <td>Timing yield estimation using statistical stat...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0-7803-8834-8</td>\n",
       "      <td>[{'_id': '53f43b03dabfaedce555bf2a', 'name': '...</td>\n",
       "      <td>...</td>\n",
       "      <td>['Delay calculation', 'Timing failure', 'Monte...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2464Vol.3</td>\n",
       "      <td>['sequential circuits', 'statistical distribut...</td>\n",
       "      <td>['http://dx.doi.org/10.1109/ISCAS.2005.1465124...</td>\n",
       "      <td>53f43b03dabfaedce555bf2a; 53f45ee9dabfaee43ecd...</td>\n",
       "      <td>Min Pan; Chris C. N. Chu; Hai Zhou</td>\n",
       "      <td>53a72e2020f7420be8c80142</td>\n",
       "      <td>ISCAS (3)</td>\n",
       "      <td>53e99784b7602d9701f3e15d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['53e9adbdb7602d97037be8a2', '53e9bb53b7602d97...</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>167</td>\n",
       "      <td>10.1109/CMPSAC.2002.1044548</td>\n",
       "      <td>Using XML to Integrate Existing Software Syste...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0-7695-1727-7</td>\n",
       "      <td>[{'_id': '548a2e3ddabfae9b40134fbc', 'name': '...</td>\n",
       "      <td>...</td>\n",
       "      <td>['XML Base', 'World Wide Web', 'XML framework'...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>172</td>\n",
       "      <td>['Internet', 'hypermedia markup languages', 'i...</td>\n",
       "      <td>['http://dx.doi.org/10.1109/CMPSAC.2002.104454...</td>\n",
       "      <td>548a2e3ddabfae9b40134fbc</td>\n",
       "      <td>Harry M. Sneed</td>\n",
       "      <td>53a72e9920f7420be8c93fac</td>\n",
       "      <td>COMPSAC</td>\n",
       "      <td>53e99784b7602d9701f3f411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['53e9a073b7602d9702957efa', '53e9ad87b7602d97...</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>en</td>\n",
       "      <td>5</td>\n",
       "      <td>506</td>\n",
       "      <td>10.1007/s11704-011-0127-6</td>\n",
       "      <td>Research on resource allocation for multi-tier...</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'_id': '53f46a22dabfaee0d9c3d5e5', 'name': '...</td>\n",
       "      <td>...</td>\n",
       "      <td>['Virtualization', 'Service level objective', ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>512</td>\n",
       "      <td>['resource allocation', 'cpu utilization', 'qu...</td>\n",
       "      <td>['http://dx.doi.org/10.1007/s11704-011-0127-6'...</td>\n",
       "      <td>53f46a22dabfaee0d9c3d5e5</td>\n",
       "      <td>Shuguo Yang</td>\n",
       "      <td>572de199d39c4f49934b3d5c</td>\n",
       "      <td>Frontiers of Computer Science in China</td>\n",
       "      <td>53e99784b7602d9701f3f5fe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          references    year lang volume  \\\n",
       "0  ['53e9a8a9b7602d97031f6bb9', '599c7b6b601a182c...  2005.0   en    NaN   \n",
       "1  ['53e9adbdb7602d97037be8a2', '53e9bb53b7602d97...  2002.0   en    NaN   \n",
       "2  ['53e9a073b7602d9702957efa', '53e9ad87b7602d97...  2011.0   en      5   \n",
       "\n",
       "  page_start                          doi  \\\n",
       "0       2461   10.1109/ISCAS.2005.1465124   \n",
       "1        167  10.1109/CMPSAC.2002.1044548   \n",
       "2        506    10.1007/s11704-011-0127-6   \n",
       "\n",
       "                                               title issue           isbn  \\\n",
       "0  Timing yield estimation using statistical stat...   NaN  0-7803-8834-8   \n",
       "1  Using XML to Integrate Existing Software Syste...   NaN  0-7695-1727-7   \n",
       "2  Research on resource allocation for multi-tier...     4            NaN   \n",
       "\n",
       "                                             authors  ...  \\\n",
       "0  [{'_id': '53f43b03dabfaedce555bf2a', 'name': '...  ...   \n",
       "1  [{'_id': '548a2e3ddabfae9b40134fbc', 'name': '...  ...   \n",
       "2  [{'_id': '53f46a22dabfaee0d9c3d5e5', 'name': '...  ...   \n",
       "\n",
       "                                                 fos n_citation   page_end  \\\n",
       "0  ['Delay calculation', 'Timing failure', 'Monte...       28.0  2464Vol.3   \n",
       "1  ['XML Base', 'World Wide Web', 'XML framework'...       28.0        172   \n",
       "2  ['Virtualization', 'Service level objective', ...        2.0        512   \n",
       "\n",
       "                                            keywords  \\\n",
       "0  ['sequential circuits', 'statistical distribut...   \n",
       "1  ['Internet', 'hypermedia markup languages', 'i...   \n",
       "2  ['resource allocation', 'cpu utilization', 'qu...   \n",
       "\n",
       "                                                 url  \\\n",
       "0  ['http://dx.doi.org/10.1109/ISCAS.2005.1465124...   \n",
       "1  ['http://dx.doi.org/10.1109/CMPSAC.2002.104454...   \n",
       "2  ['http://dx.doi.org/10.1007/s11704-011-0127-6'...   \n",
       "\n",
       "                                          author_ids  \\\n",
       "0  53f43b03dabfaedce555bf2a; 53f45ee9dabfaee43ecd...   \n",
       "1                           548a2e3ddabfae9b40134fbc   \n",
       "2                           53f46a22dabfaee0d9c3d5e5   \n",
       "\n",
       "                         author_names                  venue_id  \\\n",
       "0  Min Pan; Chris C. N. Chu; Hai Zhou  53a72e2020f7420be8c80142   \n",
       "1                      Harry M. Sneed  53a72e9920f7420be8c93fac   \n",
       "2                         Shuguo Yang  572de199d39c4f49934b3d5c   \n",
       "\n",
       "                               venue_name                        id  \n",
       "0                               ISCAS (3)  53e99784b7602d9701f3e15d  \n",
       "1                                 COMPSAC  53e99784b7602d9701f3f411  \n",
       "2  Frontiers of Computer Science in China  53e99784b7602d9701f3f5fe  \n",
       "\n",
       "[3 rows x 24 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cdd18a6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2663702, 24)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[(data[\"year\"] > 2000) & (data[\"year\"] < 2023)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "442c51fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(777972, 24)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[(data[\"year\"] > 2015) & (data[\"year\"] < 2023)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c6c279ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569108, 24)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[(data[\"year\"] > 2016) & (data[\"year\"] < 2023)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2fb9736f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(346987, 24)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[(data[\"year\"] > 2017) & (data[\"year\"] < 2023)].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff42321",
   "metadata": {},
   "source": [
    "# Take only the most recent papers to reduce the dataset for computational purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b76e3585",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[(data[\"year\"] > 2015) & (data[\"year\"] < 2023)].to_csv(\"all_data/data_2015.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "25dc2210",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[(data[\"year\"] > 2016) & (data[\"year\"] < 2023)].to_csv(\"all_data/data_2016.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "572f10f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2015 = data[(data[\"year\"] > 2015) & (data[\"year\"] < 2023)][[\"id\", \"abstract\"]].to_numpy()\n",
    "np.save(\"all_data/data_2015_abstracts.npy\", data2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "83470cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2016 = data[(data[\"year\"] > 2016) & (data[\"year\"] < 2023)][[\"id\", \"abstract\"]].to_numpy()\n",
    "np.save(\"all_data/data_2016_abstracts.npy\", data2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ced14226",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = np.load('all_data/data_2016_abstracts.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f1951d32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['53e997ddb7602d9701fd4f44',\n",
       "       'The number of states in two-way deterministic finite automata (2DFAs) is considered. It is shown that the state complexity of basic operations is: at least m+ n茂戮驴 o(m+ n) and at most 4m+ n+ 1 for union; at least m+ n茂戮驴 o(m+ n) and at most m+ n+ 1 for intersection; at least nand at most 4nfor complementation; at least $\\\\Omega(\\\\frac{m}{n}) + \\\\frac{2^{\\\\Omega(n)}}{\\\\log m}$ and at most $2m^{m+1}\\\\cdot 2^{n^{n+1}}$ for concatenation; at least $\\\\frac{1}{n} 2^{\\\\frac{n}{2}-1}$ and at most $2^{O(n^{n+1})}$ for both star and square; between nand n+ 2 for reversal; exactly 2nfor inverse homomorphism. In each case mand ndenote the number of states in 2DFAs for the arguments.'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d5e64f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = np.load('all_data/preprocessed_data_2015_abstracts.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "80eef441",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'53e997ddb7602d9701fd4f44': 'number state two way deterministic finite automata DFAs consider show state complexity basic operation least n n n union least n n n intersection least nand nfor complementation least omega frac n frac omega n log cdot n n concatenation least frac n frac n n n star square nand n reversal exactly nfor inverse homomorphism case mand ndenote number state DFAs argument',\n",
       " '53e997ddb7602d9701fd58bb': 'randomized gossip one popular way disseminate information large scale network appreciate simplicity robustness efficiency push protocol every informed node select every time step k round one neighboring node uniformly random forward information node protocol know complete information spread O log n time step high probability w h p several family n node static network Push protocol empirically show perform well practice specifically robust dynamic topological change aim analyze Push protocol dynamic network consider edge Markovian evolve graph capture natural temporal dependency structure network time one time precisely non edge appear probability p exist edge die probability q order fit real world trace mostly concentrate study case p Omega n q constant prove realistic scenario Push protocol perform well complete information spread O log n time step w h p note performance hold even network w h p disconnected every time step e g p log n n provide first formal argument demonstrate robustness Push protocol network change address range parameter p q e g p q arbitrary p q p n arbitrary q although precisely fit measure perform real world trace independent interest setting case confirm positive impact dynamism',\n",
       " '53e997e3b7602d9701fd973d': 'Vassilevska Williams STOC show count simple path k vertex matching k edge n vertex graph time nk year two different algorithm runtime give Koutis Williams ICALP bj rklund et al ESA via nst time algorithm count tuple pairwise disjoint set draw give family sized subset n element universe shortly afterwards Alon Gutner TALG show problem n st n k low bound count color coding show one well namely show meet middle exponent st beat give algorithm count time n st O multiple three imply algorithm count occurrence fix subgraph k vertex pathwidth p Lt k n vertex graph n k p time improve three mention algorithm path matching circumvent color code lower bound',\n",
       " '53e997e4b7602d9701fdd649': 'problem cover minimum cost common basis two matroid NP complete even two matroid coincide cost equal show follow special case solvable polynomial time give digraph V designate root node r V arc cost c find minimum cardinality subset H arc set h intersect every minimum c cost r arborescence algorithm give solve weighted version well nonnegative weight function w A give want find subset h arc set h intersect every minimum c cost r arborescence w H minimum run time algorithm n T n n denote number node arc input digraph T n time need minimum cut computation digraph polyhedral description give seem rather challenge',\n",
       " '53e997e4b7602d9701fddfa0': 'consider problem perform predecessor search bound universe achieve query time depend distribution query obtain several datum structure various property particular give datum structure achieve expect query time logarithmic entropy distribution query space bound term universe size well datum structure linear space query time high still sublinear function entropy structure distribution assume know consider individual query time universe element general weight well case distribution know advance',\n",
       " '53e997e8b7602d9701fe0249': 'study following Bayesian setting item sell n selfish bidder independent second price auction bidder private valuation function express complex preference subset item bidder belief valuation function bidder form probability distribution objective allocate item bidder way provide good approximation optimal social welfare value show bidder submodular valuation function every Bayesian Nash equilibrium game provide approximation optimal social welfare moreover show full information game pure Nash always exist find time polynomial n',\n",
       " '53e997e8b7602d9701fe0542': 'barrier certificate separate state space consider hybrid HS safe unsafe part accord safety property verify therefore notion widely verification hs strong condition barrier certificate bcs mean bc synthesize expressiveness synthesize bc weak hand synthesize expressive bc normally mean high complexity Kong et al investigate relax condition bc still keep convexity one synthesize expressive bc efficiently semi definite programming sdp first discuss relax condition bc general way still keep convexity thus one utilize different weak condition flexibly synthesize different kind bc expressiveness efficiently sdp give opportunity verify consider show combine two function together form combine BC order prove safety property consideration whereas neither may BC separately fact notion combine bc strictly expressive bcs far bring chance verify consider another contribution investigate avoid unsoundness sdp cause numerical error symbolic checking',\n",
       " '53e997e8b7602d9701fe177d': 'give edge weight graph g v e set e subset E incremental network design problem minimum spanning tree ask sequence edge e ldot e r e setminus e minimize sum Tw x w X weight minimum span tree x subgraph v E cup e ldot e T lvert e setminus e rvert prove problem solve greedy algorithm',\n",
       " '53e997e9b7602d9701fe5ffd': 'multi armed bandit problem predominant theoretical exploration exploitation tradeoff learn countless application range medical trial communication network web search advertising many application domain learner may constrain one supply budget limit addition customary limitation time horizon literature lack general encompass sort problem introduce call bandit knapsack combine aspect stochastic integer programming online learning distinctive feature problem comparison exist regret minimization literature optimal policy give latent distribution may significantly outperform policy play optimal fix arm consequently achieve sub linear regret bandit knapsack problem significantly challenging conventional bandit problem two algorithm whose reward close information theoretic optimum one novel balanced exploration paradigm primal dual algorithm multiplicative update Further prove regret achieve algorithm optimal polylogarithmic factor illustrate generality problem application number different domain include electronic commerce routing scheduling one example concrete application consider problem dynamic post pricing limited supply obtain first algorithm whose regret respect optimal dynamic policy sub linear supply',\n",
       " '53e997ecb7602d9701fe9b58': 'weight counting WMC well know inference task knowledge basis basis efficient technique probabilistic inference graphical introduce algebraic count AMC generalization WMC semire structure provide unified view range task exist show AMC generalize many well know task variety domain probabilistic inference soft constraint network database analysis furthermore investigate AMC knowledge compilation perspective show AMC task evaluate sd DNNF circuit strictly succinct thus efficient evaluate direct representation set identify characteristic AMC instance allow evaluation even succinct circuit'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48b9b77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
