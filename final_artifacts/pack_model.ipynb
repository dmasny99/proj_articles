{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a43fda37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "import pandas as pd\n",
    "import re\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68bacc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"all_data/data_2015.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79933af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = data.iloc[0][\"abstract\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "87b6071a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TopicModeling:\n",
    "\n",
    "    def __init__(self, path_to_model: str):\n",
    "        self.bert_model = BERTopic.load(path_to_model)\n",
    "        self.topic_dict = dict(zip(self.bert_model.get_topic_info()['Topic'], \n",
    "                                   self.bert_model.get_topic_info()['Name']))\n",
    "    \n",
    "    def text_preprocessing(self, text: str):\n",
    "        regex = re.compile('[A-Za-z]+')\n",
    "        nlp = spacy.load('en_core_web_sm')\n",
    "        mystopwords = stopwords.words('english') + ['paper', 'result', 'experiment', 'from', 'subject', \n",
    "                                                're', 'edu', 'use', 'data', 'method', 'based', \n",
    "                                                'new', 'approach', 'also','system', 'model', \n",
    "                                                'present', 'research', 'propose', 'base']\n",
    "        \n",
    "        text = ' '.join(regex.findall(text))\n",
    "        doc = nlp(text)\n",
    "        text = ' '.join([token.lemma_ for token in doc])\n",
    "        text = ' '.join([token for token in text.split() if not token in mystopwords])\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    def score_text(self, text: str):\n",
    "        text = self.text_preprocessing(text)\n",
    "        topic, prob = self.bert_model.transform(text)\n",
    "        return self.topic_dict[topic[0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "de940465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The number of states in two-way deterministic finite automata (2DFAs) is considered. It is shown that the state complexity of basic operations is: at least m+ n茂戮驴 o(m+ n) and at most 4m+ n+ 1 for union; at least m+ n茂戮驴 o(m+ n) and at most m+ n+ 1 for intersection; at least nand at most 4nfor complementation; at least $\\\\Omega(\\\\frac{m}{n}) + \\\\frac{2^{\\\\Omega(n)}}{\\\\log m}$ and at most $2m^{m+1}\\\\cdot 2^{n^{n+1}}$ for concatenation; at least $\\\\frac{1}{n} 2^{\\\\frac{n}{2}-1}$ and at most $2^{O(n^{n+1})}$ for both star and square; between nand n+ 2 for reversal; exactly 2nfor inverse homomorphism. In each case mand ndenote the number of states in 2DFAs for the arguments.'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4d1f7271",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TopicModeling(path_to_model=\"bert_model_350k_2015_new\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5aea7205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45ea6c881f3a4694a6f1f343b5b085e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'114_automata_automaton_pushdown_regular'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score_text(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "72a38d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"topic_modeling_pipeline.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4b63dd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"topic_modeling_pipeline.pkl\", \"rb\") as f:\n",
    "    m = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f8768aa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46d0fe7b146c42fd9302fa2ade68a455",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'114_automata_automaton_pushdown_regular'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.score_text(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9edcc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5625e94f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
